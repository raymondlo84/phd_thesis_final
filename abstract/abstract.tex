In this thesis, I present a new generation of Augmediated Reality Digital Eye Glass (DEG) that embodies the principles of Humanistic Intelligence (HI).  In particular, this thesis addresses the fundamental issues in the practical realization of the HI framework, most notably the dynamic range of sensors and the design of a natural human-computer interface based on three dimensional (3D) gestural input.  

First, to address the dynamic range limitation of color sensors, a practical implementation of high dynamic range (HDR) image composition and tone mapping algorithms were designed on both Field-programmable Gate Arrays (FPGAs) and Graphics Processing Units (GPUs) to enable real-time processing of video streams. The algorithms are optimized for wearable applications and provide a constant runtime performance independent of the scene. To demonstrate the robustness of the algorithm, a specialized DEG helmet was designed to work under the most extreme lighting condition - tungsten inert gas welding. 

In addition, I discuss the development of a novel HDR technique for 3D depth sensing cameras called 3DHDR.  Here, I present a method of creating 3D HDR depth maps using an array of 3D depth sensing cameras designed for wearable applications. The system provides a tonal and spatial range that significantly exceeds the capability of any individual depth sensor. 
 
Finally, I present an untethered wearable solution of DEG with 3D gestural input based on 3DHDR. The recognition system provides various modes of operations and allows users to integrate gesture-based input to control the Augmediated Reality DEG system. The final prototype has been translated to a commercially available development platform for use in future wearable computing research to further explore the HI framework. 